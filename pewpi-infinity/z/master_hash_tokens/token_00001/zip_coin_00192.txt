metcalfe, a. rest, w. e. sweeney, j. l. tonry, r. j. wainscoat, and w. m. wood-vase see 2 usage examples → atmospheric models from mã©tã©o-france agriculture climate disaster response earth observation environmental meteorological model weather global and high-resolution regional atmospheric models from mã©tã©o-france. arpege world covers the entire world at a base horizontal resolution of 0.5â° (~55km) between grid points, it predicts weather out up to 114 hours in the future. arpege europe covers europe and north-africa at a base horizontal resolution of 0.1â° (~11km) between grid points, it predicts weather out up to 114 hours in the future. arome france covers france at a base horizontal resolution of 0.025â° (~2.5km) between grid points, it predicts weather out up to 42 hours in the future. arome france hd covers france and neighborhood at a base horizontal resolution of 0.01â° (~1.5km) between grid points, it predicts weather out up to 42 hours in the future. dozens of atmospheric variables are avail... details → usage examples windguru.cz by windguru windy.com by windy see 2 usage examples → aurora multi-sensor dataset autonomous vehicles computer vision deep learning image processing lidar machine learning mapping robotics traffic transportation urban weather the aurora multi-sensor dataset is an open, large-scale multi-sensor dataset with highly accurate localization ground truth, captured between january 2017 and february 2018 in the metropolitan area of pittsburgh, pa, usa by aurora (via uber atg) in collaboration with the university of toronto. the de-identified dataset contains rich metadata, such as weather and semantic segmentation, and spans all four seasons, rain, snow, overcast and sunny days, different times of day, and a variety of traffic conditions. the aurora multi-sensor dataset contains data from a 64-beam velodyne hdl-64e lidar sensor and seven 1920x1200-pixel resolution cameras including a forward-facing stereo pair and five wide-angle lenses covering a 360-degree view around the vehicle. this data can be used to develop and evaluate large-scale long-term approaches to autonomous vehicle localization. its size and diversity make it suitable for a wide range of research areas such as 3d reconstruction, virtual tourism, hd map construction, and map compression, among others. the data was first presented at the international conference on intelligent robots an ... details → usage examples introduction to visualizing sensor types (jupyter notebook) by andrei bã¢rsan (note: aurora makes no representations as to the accuracy or functionality of the tutorial) "pit30m: a benchmark for global localization in the age of self-driving cars", in 2020 ieee/rsj international conference on intelligent robots and systems (iros) (pp. 4477-4484) by martinez, j., doubov, s., fan, j., bã¢rsan, i. a., wang, s., mã¡ttyus, g., urtasun, r. see 2 usage examples → biodiversity heritage library metadata and page images biodiversity bioinformatics life sciences the biodiversity heritage library (bhl) is the worldâs largest open access digital library for biodiversity literature and archives. bhl operates as a worldwide consortium of natural history, botanical, research, and national libraries working together to digitize the natural history literature held in their collections and make it freely available for open access. details → usage examples unearthing the past for a sustainable future: extracting and transforming data in the biodiversity heritage library for climate action by dearborn j, lichtenberg m, richard j, deveer j, trizna m, mika k biostor by roderic page ai models are getting better and better at reading handwriting, but how can we find handwritten text to begin with? by mike trizna, jj dearborn understanding bhl through metadata: patterns of bio-diverse knowledge production by lidia ponce de la vega bhlindex by global names see 5 usage examples → biological and physical sciences (bps) microscopy benchmark training dataset fluorescence imaging genelab genetic genetic maps life sciences microscopy nasa smd ai fluorescence microscopy images of individual nuclei from mouse fibroblast cells, irradiated with fe particles or x-rays with fluorescent foci indicating 53bp1 positivity, a marker of dna damage. these are maximum intensity projections of 9-layer microscopy z-stacks. details → usage examples nasa smd ai workshop report by smd artificial intelligence (ai) initiative dose, let and strain dependence of radiation-induced 53bp1 foci in 15 mouse strains ex vivo introducing novel dna damage metrics by sã©bastien penninckx, egle cekanaviciute, charlotte degorre, elodie guiet, louise viger, stã©phane lucasb, sylvain v. costes see 2 usage examples → biological and physical sciences (bps) rna sequencing benchmark training dataset gene expression genelab genetic genetic maps life sciences nasa smd ai space biology rna sequencing data from spaceflown and control mouse liver samples, sourced from nasa genelab and augmented with generative adversarial network. details → usage examples adversarial generation of gene expression data by ramon viã±as, helena andrã©s-terrã©, pietro liã², kevin bryson nasa smd ai workshop report by smd artificial intelligence (ai) initiative see 2 usage examples → brain encoding response generator (berg) brain models computer vision deep learning life sciences machine learning neuroimaging neuroscience brain encoding response generator (berg) is a resource consisting of multiple pre-trained encoding models of the brain and an accompanying python package to generate accurate in silico neural responses to arbitrary stimuli with just a few lines of code. details → usage examples in-silico fmri data tutorial by alessandro gifford in-silico eeg data tutorial by alessandro gifford the brain encoding response generator by alessandro gifford quickstart tutorial by domenic bersch brain encoding response generator (berg) by alessandro gifford see 5 usage examples → brain/minds marmoset connectivity resource on aws brain images imaging life sciences microscopy neurobiology neuroimaging neuroscience nifti non-human primate brain/minds marmoset connectivity resource (bmcr) is a resource that provides access to anterograde and retrograde neuronal tracer data, made available by brain/minds project. it is currently restricted to injections into the prefrontal cortex of a marmoset brain but is planned to include injections into entire cortical areas and representative subcortical brain regions. details → usage examples local and long-distance organization of prefrontal cortex circuits in the marmoset brain. by watakabe a, skibbe h, nakae k, abe h, ichinohe n, rachmadi mf, wang j, takaji m, mizukami h, woodward a, gong r, hata j, van essen dc, okano h, ishii s, yamamori t.